{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnWK1bAgVjc9fFdZVB/nw3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaimManzoor49/tensorflow/blob/main/LinearRegressionModel_Titanic_Predection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ivgMMQWwnvRi"
      },
      "outputs": [],
      "source": [
        "import sklearn as sl\n",
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from IPython.display import clear_output\n",
        "from six.moves import urllib\n",
        "\n",
        "import tensorflow.compat.v2.feature_column as fc\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get train data and evaluation data\n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv')\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv')\n",
        "y_train = dftrain.pop('survived')\n",
        "y_eval = dfeval.pop('survived')\n",
        "\n",
        "# seperate Categorical(true,false)||(male,female)||(any thing like that) and numerical values(1,2,5,6,7.787,454354)\n",
        "CATEGORICAL_COLUMNS = ['sex','n_siblings_spouses','parch','class','deck','embark_town','alone']\n",
        "NUMERIC_COLUMNS = ['age','fare']\n",
        "\n",
        "feature_columns = [] # formating or preparing data for training\n",
        "\n",
        "for feature_name in CATEGORICAL_COLUMNS:\n",
        "  vocabulary = dftrain[feature_name].unique() # gives all unique values in the categorical_column of name feature_name in train ds\n",
        "  feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name,vocabulary)) # addind it to FC\n",
        "\n",
        "for feature_name in NUMERIC_COLUMNS:\n",
        "  feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype=tf.float32)) # gives all unique values in the numeric_column of name feature_name in train ds\n",
        "\n",
        "# traning modal\n",
        "# input function to manage traning data into batches and epoch , encodes data in tf.data.Dataset object required for training\n",
        "\n",
        "def make_input_function(data_df,label_df,num_epochs=100,shuffle=True,batch_size=32): # returns the requires input function for traning\n",
        "  def input_function():\n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df),label_df)) # creates tf.data.Datasets object with data and its lables\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs) # split in batch size and repeat for num of epochs\n",
        "    return ds\n",
        "  return input_function\n",
        "\n",
        "\n",
        "train_input_fn = make_input_function(dftrain,y_train) # for training\n",
        "eval_input_fn = make_input_function(dfeval,y_eval,num_epochs=1,shuffle=False) # for eval\n",
        "\n",
        "# creating the modal\n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)\n",
        "\n",
        "# traning modal\n",
        "linear_est.train(train_input_fn)\n",
        "\n",
        "# evaluating the modal\n",
        "result = linear_est.evaluate(eval_input_fn)\n",
        "\n",
        "clear_output()\n",
        "print(result['accuracy'])\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jBRObPRmpkdu",
        "outputId": "af800251-c1bc-4ea3-eacb-14823c6fe1d2"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.77272725\n",
            "{'accuracy': 0.77272725, 'accuracy_baseline': 0.625, 'auc': 0.837588, 'auc_precision_recall': 0.7879456, 'average_loss': 0.47431797, 'label/mean': 0.375, 'loss': 0.45775047, 'precision': 0.6857143, 'prediction/mean': 0.41460276, 'recall': 0.72727275, 'global_step': 2000}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pridection = list(linear_est.predict(eval_input_fn))\n",
        "print(dfeval.loc[10])\n",
        "print(pridection[10]['probabilities'][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41t_SSUBOAeu",
        "outputId": "1bc06c12-3de4-4f83-bd02-0c3e30bcd9ff"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sex                       female\n",
            "age                         28.0\n",
            "n_siblings_spouses             0\n",
            "parch                          0\n",
            "fare                        7.75\n",
            "class                      Third\n",
            "deck                     unknown\n",
            "embark_town           Queenstown\n",
            "alone                          y\n",
            "Name: 10, dtype: object\n",
            "0.7193596\n"
          ]
        }
      ]
    }
  ]
}